{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìë Tutorials for PyPOTS Forecasting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÄ Preparing the **PhysioNet-2012** dataset for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 22:54:50 [INFO]: Have set the random seed as 16 for numpy and pytorch.\n",
      "2024-03-17 22:54:50 [INFO]: Loading the dataset physionet_2012 with TSDB (https://github.com/WenjieDu/Time_Series_Data_Beans)...\n",
      "2024-03-17 22:54:50 [INFO]: Starting preprocessing physionet_2012...\n",
      "2024-03-17 22:54:50 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2024-03-17 22:54:50 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2024-03-17 22:54:50 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2024-03-17 22:54:50 [INFO]: Loaded successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['n_classes', 'n_steps', 'n_features', 'train_X', 'train_y', 'train_ICUType', 'val_X', 'val_y', 'val_ICUType', 'test_X', 'test_y', 'test_ICUType', 'scaler', 'val_X_ori', 'test_X_ori', 'test_X_indicating_mask'])\n"
     ]
    }
   ],
   "source": [
    "from pypots.data.generating import gene_physionet2012\n",
    "from pypots.utils.random import set_random_seed\n",
    "from global_config import RANDOM_SEED\n",
    "\n",
    "set_random_seed(RANDOM_SEED)\n",
    "\n",
    "# Load the PhysioNet-2012 dataset\n",
    "physionet2012_dataset = gene_physionet2012()\n",
    "\n",
    "# Take a look at the generated PhysioNet-2012 dataset, you'll find that everything has been prepared for you,\n",
    "# data splitting, normalization, additional artificially-missing values for evaluation, etc.\n",
    "print(physionet2012_dataset.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the datasets for training, validating, and testing.\n",
    "\n",
    "dataset_for_training = {\n",
    "    \"X\": physionet2012_dataset['train_X'],\n",
    "}\n",
    "\n",
    "dataset_for_validating = {\n",
    "    \"X\": physionet2012_dataset['val_X'],\n",
    "    \"X_intact\": physionet2012_dataset['val_X_ori'],\n",
    "}\n",
    "\n",
    "dataset_for_testing = {\n",
    "    \"X\": physionet2012_dataset['test_X'][:, :36],  # we only take the first 36 steps for model input,\n",
    "    # and let the model forecast the left 12 steps\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ An example of **BTTF** for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 22:55:07 [INFO]: No given device, using default device: cuda\n",
      "2024-03-17 22:55:07 [WARNING]: ‚ÄºÔ∏è saving_path not given. Model files and tensorboard file will not be saved.\n"
     ]
    }
   ],
   "source": [
    "from pypots.forecasting import BTTF\n",
    "import numpy as np\n",
    "\n",
    "# initialize the model\n",
    "bttf = BTTF(\n",
    "    36,\n",
    "    physionet2012_dataset[\"n_features\"],\n",
    "    pred_step=12,\n",
    "    rank=10,\n",
    "    time_lags=[1, 2, 3, 10, 10 + 1, 10 + 2, 20, 20 + 1, 20 + 2],\n",
    "    burn_iter=5,\n",
    "    gibbs_iter=5,\n",
    "    multi_step=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wdudu/.conda/envs/ml/lib/python3.10/site-packages/pypots/forecasting/bttf/model.py:117: UserWarning: Please run func forecast(X) directly.\n",
      "  warnings.warn(\"Please run func forecast(X) directly.\")\n"
     ]
    }
   ],
   "source": [
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "bttf.fit(train_set=dataset_for_training, val_set=dataset_for_validating)\n",
    "# BTTF does not need to run func fits().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage\n",
    "bttf_results = bttf.predict(dataset_for_testing)\n",
    "bttf_prediction = bttf_results[\"forecasting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean absolute error: 1.2796\n"
     ]
    }
   ],
   "source": [
    "from pypots.utils.metrics import calc_mae\n",
    "\n",
    "# calculate the mean absolute error on the ground truth in the forecasting task\n",
    "testing_mae = calc_mae(\n",
    "    bttf_prediction,\n",
    "    np.nan_to_num(physionet2012_dataset['test_X'][:, 36:]),\n",
    "    (~np.isnan(physionet2012_dataset['test_X'][:, 36:])).astype(int),\n",
    ")\n",
    "print(f\"Testing mean absolute error: {testing_mae:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
